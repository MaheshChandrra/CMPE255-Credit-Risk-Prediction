{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "492678b0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-20T20:28:46.502842Z",
     "start_time": "2022-05-20T20:28:37.902172Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.figure_factory as ff\n",
    "import numpy as np\n",
    "from IPython.display import display\n",
    "import plotly.express as px\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import KFold, cross_validate, train_test_split\n",
    "import xgboost as xgb\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.feature_selection import SelectFromModel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "93a8a1f5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-20T20:25:37.774804Z",
     "start_time": "2022-05-20T20:25:37.769808Z"
    }
   },
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "62e74f8d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-20T20:25:40.016333Z",
     "start_time": "2022-05-20T20:25:40.000591Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.DS_Store',\n",
       " '.ipynb_checkpoints',\n",
       " 'app_models.py',\n",
       " 'CMPE 255 Credit Risk Prediction-Main.ipynb',\n",
       " 'CMPE 255 Credit Risk Prediction-Main.py',\n",
       " 'preprocessing.py',\n",
       " 'previous code',\n",
       " 'properties.py',\n",
       " 'requirements.txt',\n",
       " 'Testing.xlsx',\n",
       " 'Untitled.ipynb',\n",
       " 'util.py',\n",
       " '__pycache__']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7a897120",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-20T20:26:04.624128Z",
     "start_time": "2022-05-20T20:25:55.266006Z"
    }
   },
   "outputs": [],
   "source": [
    "df_in=pd.read_excel('Testing.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7eb725cc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-20T20:42:00.536808Z",
     "start_time": "2022-05-20T20:42:00.518036Z"
    }
   },
   "outputs": [],
   "source": [
    "result_dict={}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "83d1784f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-20T20:42:04.969371Z",
     "start_time": "2022-05-20T20:42:02.270872Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Applying One hot encoding\n",
      "[INFO] One hot encoding completed\n",
      "[INFO] Applying Upsampling\n",
      "[INFO] Upsampling Completed\n",
      "[13:42:03] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user1\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Model name: XGBClassifier\n",
      "[INFO] Results on Train:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      1.00      0.97     17722\n",
      "           1       1.00      0.94      0.97     17722\n",
      "\n",
      "    accuracy                           0.97     35444\n",
      "   macro avg       0.97      0.97      0.97     35444\n",
      "weighted avg       0.97      0.97      0.97     35444\n",
      "\n",
      "####################################################################################################\n",
      "\n",
      "[INFO] Evaluation Metrics on Train:\n",
      "\n",
      "\tAccuracy: 0.9696704660873491\n",
      "\tPrecision Score: 0.9977276804401124\n",
      "\tRecall Score: 0.9414851596885228\n",
      "\tF1 Score: 0.9687908259544201\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "[INFO] Results on Test:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.99      0.96      7595\n",
      "           1       0.94      0.74      0.83      2127\n",
      "\n",
      "    accuracy                           0.93      9722\n",
      "   macro avg       0.93      0.86      0.89      9722\n",
      "weighted avg       0.93      0.93      0.93      9722\n",
      "\n",
      "\n",
      "[INFO] Evaluation Metrics on Test:\n",
      "\tAccuracy: 0.9323184529932113\n",
      "\tPrecision Score: 0.9390316796174537\n",
      "\tRecall Score: 0.7385989656793606\n",
      "\tF1 Score: 0.8268421052631578\n",
      "\n",
      "\n",
      "####################################################################################################\n"
     ]
    }
   ],
   "source": [
    "target_column=\"loan_status\"\n",
    "CATEGORICAL_COLUMNS=[\"person_home_ownership\",\"loan_intent\",\"loan_grade\",\"cb_person_default_on_file\"]\n",
    "NUMERICAL_COLUMNS=['person_age',\n",
    " 'person_income',\n",
    " 'person_emp_length',\n",
    " 'loan_amnt',\n",
    " 'loan_int_rate',\n",
    " 'loan_percent_income']\n",
    "result_dict=apply_XGBoost(df_in,target_column,CATEGORICAL_COLUMNS,NUMERICAL_COLUMNS,result_dict)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "337807ff",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "36bb21bd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-20T20:41:50.106497Z",
     "start_time": "2022-05-20T20:41:50.083724Z"
    }
   },
   "outputs": [],
   "source": [
    "def show_results(X_tr,Y_tr,X_tst,y_tst,classifier,result_dict):\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    Author : Mareedu Mahesh Chandra\n",
    "\n",
    "    This funtion plots confusion matrix and provides classification report.\n",
    "    \n",
    "    Params:\n",
    "    -----------------\n",
    "    \n",
    "    X_tr,Y_tr,X_tst,y_tst\n",
    "    => Train and Test sets\n",
    "    \n",
    "    \n",
    "    classifier\n",
    "    =>An ML classifier used for prediction.\n",
    "    \n",
    "\n",
    "    -----------------\n",
    "    \n",
    "\n",
    "    \"\"\"\n",
    "    model_name = type(classifier).__name__\n",
    "    print(\"[INFO] Model name:\",model_name)\n",
    "    print(\"[INFO] Results on Train:\\n\")\n",
    "    y_tr_prd = classifier.predict(X_tr)\n",
    "    \n",
    "    print(classification_report(Y_tr, y_tr_prd))\n",
    "    \n",
    "    print(\"#\"*100)\n",
    "    print(\"\\n[INFO] Evaluation Metrics on Train:\\n\")\n",
    "    print(\"\\tAccuracy:\",accuracy_score(Y_tr, y_tr_prd))\n",
    "    print(\"\\tPrecision Score:\",precision_score(Y_tr, y_tr_prd))\n",
    "    print(\"\\tRecall Score:\",recall_score(Y_tr, y_tr_prd))\n",
    "    print(\"\\tF1 Score:\",f1_score(Y_tr, y_tr_prd))\n",
    "    print(\"\\n\")\n",
    "    \n",
    "    #plot_confusion_matrix(classifier, X_tr, Y_tr)\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"#\"*100)\n",
    "    \n",
    "    print(\"[INFO] Results on Test:\\n\")\n",
    "    y_tst_pred = classifier.predict(X_tst)\n",
    "    print(classification_report(y_tst, y_tst_pred))\n",
    "    \n",
    "    print(\"\\n[INFO] Evaluation Metrics on Test:\")\n",
    "\n",
    "    test_accuracy=accuracy_score(y_tst, y_tst_pred)\n",
    "    test_precision=precision_score(y_tst, y_tst_pred)\n",
    "    test_recall=recall_score(y_tst, y_tst_pred)\n",
    "    test_f1_score=f1_score(y_tst, y_tst_pred)\n",
    "    \n",
    "    result_dict[model_name]=[test_accuracy,test_precision,test_recall,test_f1_score]\n",
    "    \n",
    "\n",
    "\n",
    "    print(\"\\tAccuracy:\",test_accuracy)\n",
    "    print(\"\\tPrecision Score:\",test_precision)\n",
    "    print(\"\\tRecall Score:\",test_recall)\n",
    "    print(\"\\tF1 Score:\",test_f1_score)\n",
    "    print(\"\\n\")\n",
    "    print(\"#\"*100)\n",
    "    \n",
    "    #plot_confusion_matrix(classifier, X_tst, y_tst) \n",
    "    plt.show()\n",
    "    \n",
    "    return result_dict\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "71584bd5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-20T20:34:19.147432Z",
     "start_time": "2022-05-20T20:34:19.131802Z"
    }
   },
   "outputs": [],
   "source": [
    "def create_train_test_split(df_in,target_column):\n",
    "    \"\"\"\n",
    "    \n",
    "    Author : Mareedu Mahesh Chandra\n",
    "\n",
    "    This funtion creates train test split on the data\n",
    "    \n",
    "    Params:\n",
    "    -----------------\n",
    "    \n",
    "    df_in\n",
    "    => Input dataset\n",
    "    \n",
    "    \n",
    "    target_column\n",
    "    =>A target column used to create split on data,for separating features and target varibles.\n",
    "    \n",
    "\n",
    "    \n",
    "    Returns:\n",
    "    -----------------\n",
    "    Train test splits\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(df_in.loc[:, df_in.columns !=target_column ],\n",
    "                                                    df_in[target_column],stratify=df_in[target_column], \n",
    "                                                    test_size = 0.30, random_state = 100)\n",
    "    return X_train, X_test, y_train, y_test\n",
    "    \n",
    "def upsample(X_in,y_in):\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    Author : Mareedu Mahesh Chandra\n",
    "\n",
    "    This funtion upsamples minorty class records and balances with majority class records.\n",
    "    \n",
    "    Params:\n",
    "    -----------------\n",
    "    \n",
    "    X_in,y_in\n",
    "    => features,corresponding target variables\n",
    "    \n",
    "\n",
    "    \n",
    "    Returns:\n",
    "    -----------------\n",
    "    Balanced X_train and y_train\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    print(\"[INFO] Applying Upsampling\")\n",
    "    oversample = SMOTE()\n",
    "    X_in_upsampled, y_in_upsampled = oversample.fit_resample(X_in, y_in)\n",
    "    print(\"[INFO] Upsampling Completed\")\n",
    "    \n",
    "    return X_in_upsampled, y_in_upsampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "df26d43d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-20T20:27:28.209385Z",
     "start_time": "2022-05-20T20:27:28.200404Z"
    }
   },
   "outputs": [],
   "source": [
    "def apply_one_hot_encoding(df_in,CATEGORICAL_COLUMNS,NUMERICAL_COLUMNS):\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    Author : Mareedu Mahesh Chandra\n",
    "\n",
    "    This funtion applies one hot encoding on categorical features of the dataset.\n",
    "    \n",
    "    Params:\n",
    "    -----------------\n",
    "    \n",
    "    df_in\n",
    "    => Input dataframe\n",
    "    \n",
    "    CATEGORICAL_COLUMNS\n",
    "    => List of categorical columns\n",
    "    \n",
    "    NUMERICAL_COLUMNS\n",
    "    => List of numerical columns\n",
    "    \n",
    "\n",
    "    \n",
    "    Returns:\n",
    "    -----------------\n",
    "    dataframe with encoded values.\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    print(\"[INFO] Applying One hot encoding\")\n",
    "    ohe = OneHotEncoder(categories='auto')\n",
    "    feature_arr = ohe.fit_transform(df_in[CATEGORICAL_COLUMNS]).toarray()\n",
    "    feature_labels = ohe.categories_\n",
    "    df_encoded=pd.DataFrame(data=feature_arr,columns=ohe.get_feature_names_out())\n",
    "    df_final=df_in[NUMERICAL_COLUMNS].join(df_encoded)\n",
    "    df_final['loan_status']=df_in['loan_status']\n",
    "    \n",
    "    print(\"[INFO] One hot encoding completed\")\n",
    "    \n",
    "    \n",
    "    return df_final\n",
    "    \n",
    "    \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b469c61a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-20T20:41:44.937953Z",
     "start_time": "2022-05-20T20:41:44.922326Z"
    }
   },
   "outputs": [],
   "source": [
    "def apply_XGBoost(df_in,target_column,CATEGORICAL_COLUMNS,NUMERICAL_COLUMNS,result_dict):\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    Author : Mareedu Mahesh Chandra\n",
    "\n",
    "    This funtion performs:\n",
    "        \n",
    "        1.One hot encoding\n",
    "        2.Train test split\n",
    "        3.Upsampling\n",
    "        4.Training XGBoost\n",
    "        5.Testing model\n",
    "        \n",
    "    Params:\n",
    "    -----------------\n",
    "    \n",
    "    df_in\n",
    "    => Input dataframe\n",
    "    \n",
    "    target_column\n",
    "    =>target column in the dataset\n",
    "    \n",
    "    CATEGORICAL_COLUMNS\n",
    "    => List of categorical columns\n",
    "    \n",
    "    NUMERICAL_COLUMNS\n",
    "    => List of numerical columns\n",
    "    \n",
    "    result_dict\n",
    "    =>To track results of each model\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    ### Applying One hot encoding\n",
    "    df_in=apply_one_hot_encoding(df_in,CATEGORICAL_COLUMNS,NUMERICAL_COLUMNS)\n",
    "    \n",
    "    ### Creatig Train test splits\n",
    "    X_train, X_test, y_train, y_test=create_train_test_split(df_in,target_column)\n",
    "    \n",
    "    \n",
    "    ### Upsamplign the data\n",
    "    X_train_upsampled,y_train_upsampled=upsample(X_train,y_train)\n",
    "    \n",
    "    \n",
    "    ### Applying XGBoost\n",
    "    xgb_clf = xgb.XGBClassifier()\n",
    "    xgb_clf.fit(X_train_upsampled , y_train_upsampled)\n",
    "    \n",
    "    result_dict=show_results(X_train_upsampled,y_train_upsampled,X_test,y_test,xgb_clf,result_dict)\n",
    "    \n",
    "    return result_dict\n",
    "    \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "51f2a5d0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-20T20:27:32.672084Z",
     "start_time": "2022-05-20T20:27:32.646259Z"
    }
   },
   "outputs": [],
   "source": [
    "def apply_RFC(df_in,target_column,CATEGORICAL_COLUMNS,NUMERICAL_COLUMNS):\n",
    "    \n",
    "    \"\"\"\n",
    "    Author: Nikhil Kumar Kanisetty\n",
    "\n",
    "    This function performs:\n",
    "    - Splitting train and test\n",
    "    - Upsample the data since the data is imbalanced\n",
    "    - Train a Random Forest Classifier\n",
    "    - Predict using the above model\n",
    "\n",
    "    params:\n",
    "    df -> input_df\n",
    "    target -> target_column\n",
    "    CATEGORICAL_COLUMNS -> all the categorical columns in the data\n",
    "    NUMERICAL_COLUMNS -> all the numereical columns in the data\n",
    "    \"\"\"\n",
    "    df_in = apply_one_hot_encoding(df_in, CATEGORICAL_COLUMNS, NUMERICAL_COLUMNS)\n",
    "\n",
    "    X_train, X_test, y_train, y_test = create_train_test_split(df_in, target_column)\n",
    "\n",
    "    X_train_upsampled, y_train_upsampled = upsample(X_train, y_train)\n",
    "    \n",
    "    print(\"**RANDOM FOREST CLASSIFIER with max_depth = 3**\")\n",
    "    rf = RandomForestClassifier(max_depth = 3, random_state = 100)\n",
    "    rf.fit(X_train_upsampled, y_train_upsampled)\n",
    "\n",
    "    show_results(X_train_upsampled, y_train_upsampled, X_test, y_test, rf)\n",
    "    \n",
    "#     grid_search = GridSearchCV(RandomForestClassifier(), {\n",
    "#                     \"n_estimators\": range(100, 300, 100),\n",
    "#                     \"max_depth\": range(2, 20, 2),\n",
    "#                     \"max_features\": range(1, 4),\n",
    "#                     'criterion': [\"gini\", \"entropy\"]\n",
    "#                     }, cv = 5, n_jobs = -1, verbose = 2)\n",
    "#     grid_search.fit(X_train_upsampled, y_train_upsampled)\n",
    "#     print(f\"Parameters after hyper parameter tuning: {grid_search.best_params_}\")\n",
    "\n",
    "#    {'criterion': 'entropy', 'max_depth': 18, 'max_features': 3, 'n_estimators': 200}\n",
    "    print(\"**RANDOM FOREST CLASSIFIER after hyper parameter tuning using GridSearch**\")\n",
    "    rf = RandomForestClassifier(n_estimators = 200, max_features = 3, max_depth = 18, criterion = \"entropy\", random_state = 100)\n",
    "    rf.fit(X_train_upsampled, y_train_upsampled)\n",
    "    \n",
    "    show_results(X_train_upsampled, y_train_upsampled, X_test, y_test, rf)\n",
    "    \n",
    "    select_features = SelectFromModel(RandomForestClassifier(n_estimators = 200, max_features = 3, max_depth = 18,\n",
    "                                                             criterion = \"gini\", random_state = 100))\n",
    "    select_features.fit(X_train_upsampled, y_train_upsampled)\n",
    "    \n",
    "    df = df_in.drop(columns = 'loan_status', axis = 1)\n",
    "    columns = df.columns[(select_features.get_support())]\n",
    "    \n",
    "    print(f\"Top Features: {columns}\")\n",
    "    print()\n",
    "\n",
    "    X_train_upsampled = X_train_upsampled[columns]\n",
    "    X_test = X_test[columns]\n",
    "    \n",
    "    print(\"**RANDOM FOREST CLASSIFIER with only top features**\")    \n",
    "    rf.fit(X_train_upsampled, y_train_upsampled)\n",
    "    \n",
    "    show_results(X_train_upsampled, y_train_upsampled, X_test, y_test, rf)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5c91b65d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-20T20:27:35.548301Z",
     "start_time": "2022-05-20T20:27:35.525501Z"
    }
   },
   "outputs": [],
   "source": [
    "   \n",
    "\n",
    "def apply_dt(df_in,target_column,CATEGORICAL_COLUMNS,NUMERICAL_COLUMNS):\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    Author : Lokesh Vaddi\n",
    "\n",
    "    This funtion performs:\n",
    "        \n",
    "        1.One hot encoding\n",
    "        2.Train test split\n",
    "        3.Upsampling\n",
    "        4.Training Decision Tree Classifier\n",
    "        5.Testing model\n",
    "        \n",
    "    Params:\n",
    "    -----------------\n",
    "    \n",
    "    df_in\n",
    "    => Input dataframe\n",
    "    \n",
    "    target_column\n",
    "    =>target column in the dataset\n",
    "    \n",
    "    CATEGORICAL_COLUMNS\n",
    "    => List of categorical columns\n",
    "    \n",
    "    NUMERICAL_COLUMNS\n",
    "    => List of numerical columns\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    ### Applying One hot encoding\n",
    "    df_in = apply_one_hot_encoding(df_in, CATEGORICAL_COLUMNS, NUMERICAL_COLUMNS)\n",
    "    \n",
    "    ### Creating Train test splits\n",
    "    X_train, X_test, y_train, y_test = create_train_test_split(df_in, target_column)\n",
    "    \n",
    "    ### Upsampling the Data\n",
    "    X_train_upsampled, y_train_upsampled = upsample(X_train, y_train)\n",
    "    \n",
    "    ### Applying Decision Tree Classifier\n",
    "    credit_tree = DecisionTreeClassifier(criterion='entropy')\n",
    "    credit_tree.fit(X_train_upsampled, y_train_upsampled)\n",
    "    \n",
    "    ### Results\n",
    "    show_results(X_train_upsampled, y_train_upsampled, X_test, y_test, credit_tree)\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdd5523c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
